# Edwith 조경현 교수님 강의 정리

## Index

1. [Introduction]( https://github.com/KhelKim/basic-nlp/tree/master/edwith/01 )
   1. introduction
2. [Basic Machine Learning: Supervised Learning]( https://github.com/KhelKim/basic-nlp/tree/master/edwith/02 )
   1. Overview
   2. Hypothesis Set
   3. Loss Function - Preview
   4. Probability in 5 minutes
   5. Loss Function
   6. Optimization Methods
   7. Backpropagation
   8. Gradient-Based Optimization
   9. Summary
   10. Questions
3. Text Classification & Sentence Representation
   1. Overview
   2. How to represent sentence & token?
   3. CBoW & RN & CNN
   4. Self Attention & RNN
   5. Summary
   6. Questions
4. Neural Language Models
   1. Overview: Language Modelling
   2. Autoregressive language modelling
   3. N-Gram Language Models
   4. Neural N-Gram Language Model
   5. Long Term Dependency
   6. Summary
   7. Questions
5. Neural Machine Translation
   1. Overview: a bit of history remark
   2. Encoder & Decoder
   3. RNN Neural Machine Translation
   4. Questions
6. Case Study
   1. Learning to Describe Multimedia
   2. Fully Character-Level Machine Translation
   3. Meta-Learning of Low-Resource Neural Machine Translation
   4. Real-Time Translation Learning to Decode
   5. Questions
7. Finishing the lecture
   1. Finishing the lecture

