# BASIC NLP

1. [조경현 교수님 edwith 강의]( https://github.com/KhelKim/basic-nlp/tree/master/edwith )
   1. Introduction
      1. introduction
   2. Basic Machine Learning: Supervised Learning
      1. Overview
      2. Hypothesis Set
      3. Loss Function - Preview
      4. Probability in 5 minutes
      5. Loss Function
      6. Optimization Methods
      7. Backpropagation
      8. Gradient-Based Optimization
      9. Summary
      10. Questions
   3. Text Classification & Sentence Representation
      1. Overview
      2. How to represent sentence & token?
      3. CBoW & RN & CNN
      4. Self Attention & RNN
      5. Summary
      6. Questions
   4. Neural Language Models
      1. Overview: Language Modelling
      2. Autoregressive language modelling
      3. N-Gram Language Models
      4. Neural N-Gram Language Model
      5. Long Term Dependency
      6. Summary
      7. Questions
   5. Neural Machine Translation
      1. Overview: a bit of history remark
      2. Encoder & Decoder
      3. RNN Neural Machine Translation
      4. Questions
   6. Case Study
      1. Learning to Describe Multimedia
      2. Fully Character-Level Machine Translation
      3. Meta-Learning of Low-Resource Neural Machine Translation
      4. Real-Time Translation Learning to Decode
      5. Questions
   7. Finishing the lecture
      1. Finishing the lecture
2. [Seq2Seq]( https://github.com/KhelKim/basic-nlp/tree/master/seq2seq )
   1. Seq2Seq 개요
   2. Preliminary
      1. RNN 구조
         1. Seq2Vec
         2. Vec2Seq
      2. GRU
   3. Seq2Seq
   4. 부록
      1. BLUE
3. [Attention](https://github.com/KhelKim/basic-nlp/tree/master/attention)
   1. Attention 개요
   2. Attention
   3. BiLSTM
      1. BiRNN
      2. LSTM

