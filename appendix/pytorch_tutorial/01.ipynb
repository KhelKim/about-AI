{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0653e-38, 1.0194e-38, 8.4490e-39],\n",
      "        [9.6429e-39, 8.4490e-39, 9.6429e-39],\n",
      "        [9.2755e-39, 1.0286e-38, 9.0919e-39],\n",
      "        [8.9082e-39, 9.2755e-39, 8.4490e-39],\n",
      "        [1.0194e-38, 9.0919e-39, 8.4490e-39]])\n"
     ]
    }
   ],
   "source": [
    "# 초기화되지 않은 5x3 행렬 생성하기\n",
    "\n",
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4871, 0.0296, 0.8652],\n",
      "        [0.1766, 0.2242, 0.9541],\n",
      "        [0.1308, 0.7295, 0.4894],\n",
      "        [0.1296, 0.7274, 0.9093],\n",
      "        [0.4801, 0.3368, 0.0130]])\n"
     ]
    }
   ],
   "source": [
    "# 무작위로 초기화된 행렬 생성하기\n",
    "\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "\n",
      "tensor([[[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dtype이 logn이고 0으로 채워진 행렬을 생성하기\n",
    "\n",
    "x1 = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x1)\n",
    "print()\n",
    "\n",
    "x2 = torch.zeros(5, 3, 2, dtype=torch.long)\n",
    "print(x2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "# 데이터로부터 tensor를 직접 생성하기\n",
    "\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "first's dtype:  torch.float32\n",
      "x1's dtype:  torch.float64\n",
      "\n",
      "tensor([[-0.5836,  1.1725,  0.1872],\n",
      "        [ 0.6518, -1.5275,  0.6557],\n",
      "        [-0.8890, -1.0717,  0.8255],\n",
      "        [-1.1542,  0.0907, -0.6982],\n",
      "        [-0.1601, -0.2328,  0.1649]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 존재하는 tensor를 바탕으로 tensor 만들기\n",
    "# 이 메소드들은 사용자로부터 제공된 새로운 값이 없는한, 입력 tensor의 속성들(예. dtype)을 재사용한다.\n",
    "first = torch.rand(5, 3)\n",
    "\n",
    "x1 = first.new_ones(5, 3, dtype=torch.double)  # new_* 메소드는 크기를 받는다.\n",
    "print(x1)\n",
    "print(\"first's dtype: \", first.dtype)\n",
    "print(\"x1's dtype: \", x1.dtype)\n",
    "print()\n",
    "\n",
    "x2 = torch.randn_like(first, dtype=torch.float)  # dtype을 오버라이드(Override) 한다\n",
    "print(x2)  # 결과는 동일한 크기\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# 행렬의 크기 구하기\n",
    "\n",
    "print(x2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연산(Operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5166, 0.8686, 0.8824],\n",
      "        [0.7004, 0.5558, 0.1376],\n",
      "        [1.0612, 0.7795, 0.7097],\n",
      "        [1.4036, 0.9720, 0.7216],\n",
      "        [0.1964, 0.7163, 0.2501]])\n"
     ]
    }
   ],
   "source": [
    "# 덧셈: 문법 1\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5166, 0.8686, 0.8824],\n",
      "        [0.7004, 0.5558, 0.1376],\n",
      "        [1.0612, 0.7795, 0.7097],\n",
      "        [1.4036, 0.9720, 0.7216],\n",
      "        [0.1964, 0.7163, 0.2501]])\n"
     ]
    }
   ],
   "source": [
    "# 덧셈: 문법 2\n",
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5166, 0.8686, 0.8824],\n",
      "        [0.7004, 0.5558, 0.1376],\n",
      "        [1.0612, 0.7795, 0.7097],\n",
      "        [1.4036, 0.9720, 0.7216],\n",
      "        [0.1964, 0.7163, 0.2501]])\n"
     ]
    }
   ],
   "source": [
    "# 덧셈: 결과 tensor를 인자로 제공\n",
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5166, 0.8686, 0.8824],\n",
      "        [0.7004, 0.5558, 0.1376],\n",
      "        [1.0612, 0.7795, 0.7097],\n",
      "        [1.4036, 0.9720, 0.7216],\n",
      "        [0.1964, 0.7163, 0.2501]])\n"
     ]
    }
   ],
   "source": [
    "# 덧셈: 바꿔치기 (in-place) 방식\n",
    "y.add_(x)\n",
    "print(y)\n",
    "\n",
    "# 바꿔치기 (in-place) 방식으로 tensor의 값을 변경하는 연산은\n",
    "# _ 를 접미사로 갖는다.\n",
    "# ex) x.copy_(y), x.t_()는 x를 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5897,  1.1917,  0.8302,  0.3808],\n",
      "        [-1.5184, -0.1578, -0.5871,  2.0532],\n",
      "        [-0.9585, -0.7901, -1.3423, -0.2134],\n",
      "        [-0.0964, -0.4967,  0.3805, -1.0302]])\n",
      "\n",
      "tensor([ 1.5897,  1.1917,  0.8302,  0.3808, -1.5184, -0.1578, -0.5871,  2.0532,\n",
      "        -0.9585, -0.7901, -1.3423, -0.2134, -0.0964, -0.4967,  0.3805, -1.0302])\n",
      "tensor([[ 1.5897,  1.1917,  0.8302,  0.3808, -1.5184, -0.1578, -0.5871,  2.0532],\n",
      "        [-0.9585, -0.7901, -1.3423, -0.2134, -0.0964, -0.4967,  0.3805, -1.0302]])\n",
      "\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "# 크기 변경: tensor의 크기(size)나 모양(shape)을 변경한다면 torch.view를 사용\n",
    "\n",
    "x = torch.randn(4, 4)\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(y)\n",
    "print(z)\n",
    "print()\n",
    "\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6734])\n",
      "1.6734298467636108\n",
      "tensor(1.6734)\n"
     ]
    }
   ],
   "source": [
    "# 만약 tensor에 하나의 값만 존재한다면, .item()을 사용하여 숫자 값을 얻을 수 있음\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function rand:\n",
      "\n",
      "rand(...)\n",
      "    rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "    \n",
      "    Returns a tensor filled with random numbers from a uniform distribution\n",
      "    on the interval :math:`[0, 1)`\n",
      "    \n",
      "    The shape of the tensor is defined by the variable argument :attr:`size`.\n",
      "    \n",
      "    Args:\n",
      "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "            Can be a variable number of arguments or a collection like a list or tuple.\n",
      "        out (Tensor, optional): the output tensor\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "            Default: ``torch.strided``.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.rand(4)\n",
      "        tensor([ 0.5204,  0.2503,  0.3525,  0.5673])\n",
      "        >>> torch.rand(2, 3)\n",
      "        tensor([[ 0.8237,  0.5781,  0.6879],\n",
      "                [ 0.3816,  0.7249,  0.0998]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function randn:\n",
      "\n",
      "randn(...)\n",
      "    randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
      "    \n",
      "    Returns a tensor filled with random numbers from a normal distribution\n",
      "    with mean `0` and variance `1` (also called the standard normal\n",
      "    distribution).\n",
      "    \n",
      "    .. math::\n",
      "        \\text{out}_{i} \\sim \\mathcal{N}(0, 1)\n",
      "    \n",
      "    The shape of the tensor is defined by the variable argument :attr:`size`.\n",
      "    \n",
      "    Args:\n",
      "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
      "            Can be a variable number of arguments or a collection like a list or tuple.\n",
      "        out (Tensor, optional): the output tensor\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
      "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
      "            Default: ``torch.strided``.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.randn(4)\n",
      "        tensor([-2.1436,  0.9966,  2.3426, -0.6366])\n",
      "        >>> torch.randn(2, 3)\n",
      "        tensor([[ 1.5954,  2.8929, -1.0923],\n",
      "                [ 1.1719, -0.4709, -0.1996]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.randn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# numpy 변환 (Bridge)\n",
    "\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy 배열을 torch tensor로 변환하기\n",
    "import numpy as np\n",
    "\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
